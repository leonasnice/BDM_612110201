{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ndf = pd.read_csv('https://raw.githubusercontent.com/plenoi/CMU_DataScience/master/lung.csv?fbclid=IwAR1eS1GDDvk2XHzLVB_VyO_SnydiuFcdkIo_P3D0kg6j5LvAjXpYGbEOHQo', header = None)\ndf_clean = df\ny = df_clean[0].values                       ## แยก X,y จาก Class\nX = df_clean.drop([0],axis = 1).values","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from imblearn.over_sampling import SMOTE   ## ใช้เมื่อ Class ไม่เท่ากัน\nsm = SMOTE(random_state=1)\nX, y =sm.fit_resample(X,y)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split                                    # Separate Data into Train & Test (Note: Imbalance Dataset)\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler    \nscaler = MinMaxScaler(feature_range=(0, 1))\nscaler.fit(X_train)\nX_train_norm = scaler.transform(X_train)\nX_test_norm = scaler.transform(X_test)","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV\nparams = {\n    'C' : [1, 2, 4, 8, 16, 32], # High C = Overfitting\n    'gamma' : [0.03125, 0.0625, 0.125, 0.25, 0.5, 1, 2, 4, 8, 16, 32] # High gamma = Overfitting\n}\nclf = GridSearchCV(SVC(),params, cv=10)\nclf.fit(X_train_norm, y_train)\nprint(\"Best params : \" + str(clf.best_params_))\nprint(\"10CV accuracy : \"+str(clf.best_score_*100))","execution_count":6,"outputs":[{"output_type":"stream","text":"Best params : {'C': 32, 'gamma': 0.03125}\n10CV accuracy : 74.81132075471699\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\ny_predict = clf.predict(X_test_norm)\ntarget_names = ['negative', 'positive']\nsum(y_test == y_predict)/len(y_test)*100","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"79.54545454545455"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Blind test"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('https://raw.githubusercontent.com/plenoi/CMU_DataScience/master/lung_test.csv?fbclid=IwAR1CpkdjzdhmjGxNetyDpgUrxBYkHDj8GSpRTyxnNqpXmsJvyerWYR4VCpU', header = None)\ndf_test","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"     0         1         2         3         4         5         6     \\\n0       1 -0.979046 -0.716633 -0.981584 -0.961070 -0.964285 -0.962839   \n1       1 -0.887534 -0.057599 -0.963168 -0.941605 -0.958333 -0.915544   \n2       1 -0.976713 -0.802425 -0.970534 -0.985401 -0.988095 -0.961150   \n3       1 -0.961500 -0.645135 -0.944753 -0.902674 -0.970238 -0.917232   \n4       1 -0.958373 -0.249974 -0.845303 -0.892944 -0.904763 -0.903720   \n..    ...       ...       ...       ...       ...       ...       ...   \n267     0 -0.945586  0.230922 -0.454894 -0.489033 -0.607139 -0.505091   \n268     0 -0.942505 -0.586638 -0.790055 -0.742090 -0.648807 -0.826015   \n269     0 -0.988380 -0.857016 -0.922653 -0.863746 -0.875001 -0.932435   \n270     0 -0.972186 -0.915509 -0.896870 -0.888077 -0.821427 -0.934124   \n271     0 -0.950626 -0.613945 -0.841619 -0.746957 -0.648807 -0.881761   \n\n         7         8         9     ...      1271      1272      1273  \\\n0   -0.849486 -0.900600 -0.732778  ... -0.007953 -0.835510 -0.991348   \n1   -0.473192 -0.694227 -0.081178  ...  0.137629 -0.508157 -0.921880   \n2   -0.831243 -0.907733 -0.740678  ...  0.281941 -0.770071 -0.989058   \n3   -0.753708 -0.845328 -0.591923  ...  0.445740 -0.560465 -0.972264   \n4   -0.377416 -0.864943 -0.286527  ...  0.357187 -0.798273 -0.983715   \n..        ...       ...       ...  ...       ...       ...       ...   \n267 -0.069551 -0.778469  0.136026  ... -0.422793 -0.180304 -0.929768   \n268 -0.231462 -0.941610 -0.523474  ...  0.106617 -0.823535 -0.990712   \n269 -0.559865 -0.957211 -0.820971  ...  0.453743 -0.800414 -0.995038   \n270 -0.765102 -0.987074 -0.905221  ...  0.660038 -0.796146 -0.995165   \n271 -0.359169 -0.946959 -0.519530  ...  0.038064 -0.853379 -0.989949   \n\n         1274      1275      1276      1277      1278      1279      1280  \n0   -0.860071 -0.925373 -1.000000 -1.000000 -0.581632 -0.841275 -0.997440  \n1   -0.315089  0.074620 -0.897059 -0.949368 -0.727701 -0.545253 -0.966538  \n2   -0.701209 -0.932835 -1.000000 -0.996383 -0.749610 -0.756818 -0.993245  \n3   -0.674904 -0.305949 -0.872551 -0.949368 -0.640058 -0.580938 -0.991529  \n4   -0.585479 -0.365677 -0.833334 -0.887884 -0.826811 -0.819876 -0.996596  \n..        ...       ...       ...       ...       ...       ...       ...  \n267 -0.335076  1.089560 -0.049037 -0.385160 -0.342718 -0.081677 -0.855971  \n268 -0.900055 -0.813437 -0.936275 -0.898733 -0.586853 -0.836350 -0.998654  \n269 -0.936874 -0.738810 -0.926472 -0.945752 -0.744389 -0.826324 -0.998681  \n270 -0.956864 -0.888063 -0.975490 -0.938516 -0.907145 -0.793863 -0.996860  \n271 -0.860071 -0.716418 -0.887256 -0.905969 -0.745433 -0.871529 -0.998918  \n\n[272 rows x 1281 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>1271</th>\n      <th>1272</th>\n      <th>1273</th>\n      <th>1274</th>\n      <th>1275</th>\n      <th>1276</th>\n      <th>1277</th>\n      <th>1278</th>\n      <th>1279</th>\n      <th>1280</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>-0.979046</td>\n      <td>-0.716633</td>\n      <td>-0.981584</td>\n      <td>-0.961070</td>\n      <td>-0.964285</td>\n      <td>-0.962839</td>\n      <td>-0.849486</td>\n      <td>-0.900600</td>\n      <td>-0.732778</td>\n      <td>...</td>\n      <td>-0.007953</td>\n      <td>-0.835510</td>\n      <td>-0.991348</td>\n      <td>-0.860071</td>\n      <td>-0.925373</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.581632</td>\n      <td>-0.841275</td>\n      <td>-0.997440</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>-0.887534</td>\n      <td>-0.057599</td>\n      <td>-0.963168</td>\n      <td>-0.941605</td>\n      <td>-0.958333</td>\n      <td>-0.915544</td>\n      <td>-0.473192</td>\n      <td>-0.694227</td>\n      <td>-0.081178</td>\n      <td>...</td>\n      <td>0.137629</td>\n      <td>-0.508157</td>\n      <td>-0.921880</td>\n      <td>-0.315089</td>\n      <td>0.074620</td>\n      <td>-0.897059</td>\n      <td>-0.949368</td>\n      <td>-0.727701</td>\n      <td>-0.545253</td>\n      <td>-0.966538</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>-0.976713</td>\n      <td>-0.802425</td>\n      <td>-0.970534</td>\n      <td>-0.985401</td>\n      <td>-0.988095</td>\n      <td>-0.961150</td>\n      <td>-0.831243</td>\n      <td>-0.907733</td>\n      <td>-0.740678</td>\n      <td>...</td>\n      <td>0.281941</td>\n      <td>-0.770071</td>\n      <td>-0.989058</td>\n      <td>-0.701209</td>\n      <td>-0.932835</td>\n      <td>-1.000000</td>\n      <td>-0.996383</td>\n      <td>-0.749610</td>\n      <td>-0.756818</td>\n      <td>-0.993245</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>-0.961500</td>\n      <td>-0.645135</td>\n      <td>-0.944753</td>\n      <td>-0.902674</td>\n      <td>-0.970238</td>\n      <td>-0.917232</td>\n      <td>-0.753708</td>\n      <td>-0.845328</td>\n      <td>-0.591923</td>\n      <td>...</td>\n      <td>0.445740</td>\n      <td>-0.560465</td>\n      <td>-0.972264</td>\n      <td>-0.674904</td>\n      <td>-0.305949</td>\n      <td>-0.872551</td>\n      <td>-0.949368</td>\n      <td>-0.640058</td>\n      <td>-0.580938</td>\n      <td>-0.991529</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>-0.958373</td>\n      <td>-0.249974</td>\n      <td>-0.845303</td>\n      <td>-0.892944</td>\n      <td>-0.904763</td>\n      <td>-0.903720</td>\n      <td>-0.377416</td>\n      <td>-0.864943</td>\n      <td>-0.286527</td>\n      <td>...</td>\n      <td>0.357187</td>\n      <td>-0.798273</td>\n      <td>-0.983715</td>\n      <td>-0.585479</td>\n      <td>-0.365677</td>\n      <td>-0.833334</td>\n      <td>-0.887884</td>\n      <td>-0.826811</td>\n      <td>-0.819876</td>\n      <td>-0.996596</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>267</th>\n      <td>0</td>\n      <td>-0.945586</td>\n      <td>0.230922</td>\n      <td>-0.454894</td>\n      <td>-0.489033</td>\n      <td>-0.607139</td>\n      <td>-0.505091</td>\n      <td>-0.069551</td>\n      <td>-0.778469</td>\n      <td>0.136026</td>\n      <td>...</td>\n      <td>-0.422793</td>\n      <td>-0.180304</td>\n      <td>-0.929768</td>\n      <td>-0.335076</td>\n      <td>1.089560</td>\n      <td>-0.049037</td>\n      <td>-0.385160</td>\n      <td>-0.342718</td>\n      <td>-0.081677</td>\n      <td>-0.855971</td>\n    </tr>\n    <tr>\n      <th>268</th>\n      <td>0</td>\n      <td>-0.942505</td>\n      <td>-0.586638</td>\n      <td>-0.790055</td>\n      <td>-0.742090</td>\n      <td>-0.648807</td>\n      <td>-0.826015</td>\n      <td>-0.231462</td>\n      <td>-0.941610</td>\n      <td>-0.523474</td>\n      <td>...</td>\n      <td>0.106617</td>\n      <td>-0.823535</td>\n      <td>-0.990712</td>\n      <td>-0.900055</td>\n      <td>-0.813437</td>\n      <td>-0.936275</td>\n      <td>-0.898733</td>\n      <td>-0.586853</td>\n      <td>-0.836350</td>\n      <td>-0.998654</td>\n    </tr>\n    <tr>\n      <th>269</th>\n      <td>0</td>\n      <td>-0.988380</td>\n      <td>-0.857016</td>\n      <td>-0.922653</td>\n      <td>-0.863746</td>\n      <td>-0.875001</td>\n      <td>-0.932435</td>\n      <td>-0.559865</td>\n      <td>-0.957211</td>\n      <td>-0.820971</td>\n      <td>...</td>\n      <td>0.453743</td>\n      <td>-0.800414</td>\n      <td>-0.995038</td>\n      <td>-0.936874</td>\n      <td>-0.738810</td>\n      <td>-0.926472</td>\n      <td>-0.945752</td>\n      <td>-0.744389</td>\n      <td>-0.826324</td>\n      <td>-0.998681</td>\n    </tr>\n    <tr>\n      <th>270</th>\n      <td>0</td>\n      <td>-0.972186</td>\n      <td>-0.915509</td>\n      <td>-0.896870</td>\n      <td>-0.888077</td>\n      <td>-0.821427</td>\n      <td>-0.934124</td>\n      <td>-0.765102</td>\n      <td>-0.987074</td>\n      <td>-0.905221</td>\n      <td>...</td>\n      <td>0.660038</td>\n      <td>-0.796146</td>\n      <td>-0.995165</td>\n      <td>-0.956864</td>\n      <td>-0.888063</td>\n      <td>-0.975490</td>\n      <td>-0.938516</td>\n      <td>-0.907145</td>\n      <td>-0.793863</td>\n      <td>-0.996860</td>\n    </tr>\n    <tr>\n      <th>271</th>\n      <td>0</td>\n      <td>-0.950626</td>\n      <td>-0.613945</td>\n      <td>-0.841619</td>\n      <td>-0.746957</td>\n      <td>-0.648807</td>\n      <td>-0.881761</td>\n      <td>-0.359169</td>\n      <td>-0.946959</td>\n      <td>-0.519530</td>\n      <td>...</td>\n      <td>0.038064</td>\n      <td>-0.853379</td>\n      <td>-0.989949</td>\n      <td>-0.860071</td>\n      <td>-0.716418</td>\n      <td>-0.887256</td>\n      <td>-0.905969</td>\n      <td>-0.745433</td>\n      <td>-0.871529</td>\n      <td>-0.998918</td>\n    </tr>\n  </tbody>\n</table>\n<p>272 rows × 1281 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"yt = df_clean[0].values                       ## แยก X,y จาก Class\nXt = df_clean.drop([0],axis = 1).values","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_norm = scaler.transform(Xt)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\ny_predict = clf.predict(X_test_norm)\ntarget_names = ['negative', 'positive']\nsum(yt == y_predict)/len(yt)*100","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"88.92405063291139"},"metadata":{}}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}